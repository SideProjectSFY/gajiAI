"""
ìºë¦­í„° í˜ë¥´ì†Œë‚˜ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ origin_txtì˜ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ê³ ,
char_graphì˜ ì¸ë¬¼ ê´€ê³„ë„ë¥¼ ë¶„ì„í•˜ì—¬ id 1, 2ì¸ ìºë¦­í„°ì˜
í˜ë¥´ì†Œë‚˜ì™€ speaking_styleì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import sys
import time
from pathlib import Path
from typing import Dict, List, Optional
from google import genai
from google.genai.types import Tool, FileSearch

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = Path(__file__).parent
project_root = current_dir.parent
sys.path.insert(0, str(project_root))

from app.services.api_key_manager import get_api_key_manager


class CharacterPersonaGenerator:
    """ìºë¦­í„° í˜ë¥´ì†Œë‚˜ ìƒì„±ê¸°"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.api_key_manager = get_api_key_manager()
        self.api_key = self.api_key_manager.get_current_key()
        self.client = genai.Client(api_key=self.api_key)
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
        self.project_root = project_root
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        self.data_dir = self.project_root / "data"
        self.origin_txt_dir = self.data_dir / "origin_txt"
        self.char_graph_dir = self.data_dir / "char_graph"
        self.characters_dir = self.data_dir / "characters"
        
        # characters ë””ë ‰í† ë¦¬ ìƒì„±
        self.characters_dir.mkdir(parents=True, exist_ok=True)
        
        # File Search Store ì •ë³´ ë¡œë“œ
        self._load_store_info()
    
    def _load_store_info(self):
        """File Search Store ì •ë³´ ë¡œë“œ"""
        # í˜„ì¬ API í‚¤ ì¸ë±ìŠ¤ì— ë§ëŠ” Store ì •ë³´ íŒŒì¼ ì°¾ê¸°
        current_key_index = self.api_key_manager.current_key_index
        store_info_path = self.data_dir / f"file_search_store_info_key{current_key_index + 1}.json"
        
        if not store_info_path.exists():
            store_info_path = self.data_dir / "file_search_store_info.json"
        
        try:
            with open(store_info_path, 'r', encoding='utf-8') as f:
                store_info = json.load(f)
                self.store_name = store_info.get('store_name')
        except FileNotFoundError:
            self.store_name = None
            print(f"âš ï¸ File Search Store ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {store_info_path}")
            print("   'py scripts/setup_file_search.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ Storeë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    
    def _call_llm_with_file_search(self, prompt: str, system_instruction: str = None) -> str:
        """
        File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ LLM í˜¸ì¶œ
        
        Args:
            prompt: í”„ë¡¬í”„íŠ¸
            system_instruction: ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        
        Returns:
            LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        max_retries = len(self.api_key_manager.api_keys)
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # í˜„ì¬ API í‚¤ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                current_key = self.api_key_manager.get_current_key()
                
                # API í‚¤ê°€ ë³€ê²½ë˜ì—ˆìœ¼ë©´ í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„± ë° Store ì •ë³´ ë‹¤ì‹œ ë¡œë“œ
                if current_key != self.api_key:
                    self.api_key = current_key
                    self.client = genai.Client(api_key=self.api_key)
                    self._load_store_info()
                
                if not self.store_name:
                    raise ValueError("File Search Storeê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                
                # ê¸°ë³¸ ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­
                if system_instruction is None:
                    system_instruction = """You are a literary character analyst specializing in creating detailed character personas and speaking styles based on original text sources.
You MUST use File Search to find information from the original text before answering.
Be thorough, accurate, and base your analysis on concrete evidence from the source material."""
                
                # API í˜¸ì¶œ
                response = self.client.models.generate_content(
                    model="gemini-2.5-flash",
                    contents=[{"role": "user", "parts": [{"text": prompt}]}],
                    config={
                        "system_instruction": system_instruction,
                        "tools": [
                            Tool(
                                file_search=FileSearch(
                                    file_search_store_names=[self.store_name]
                                )
                            )
                        ],
                        "temperature": 0.7,
                        "top_p": 0.95,
                        "max_output_tokens": 4096
                    }
                )
                
                # ì‘ë‹µ ì¶”ì¶œ
                response_text = ""
                if hasattr(response, 'text') and response.text:
                    response_text = response.text
                elif hasattr(response, 'candidates') and len(response.candidates) > 0:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and candidate.content:
                        if hasattr(candidate.content, 'parts') and candidate.content.parts:
                            for part in candidate.content.parts:
                                if hasattr(part, 'text') and part.text:
                                    response_text += part.text
                
                if not response_text or not response_text.strip():
                    raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                
                return response_text.strip()
                
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # í• ë‹¹ëŸ‰ ì—ëŸ¬ ì²˜ë¦¬
                if self.api_key_manager._is_quota_error(e):
                    if attempt < max_retries - 1:
                        if self.api_key_manager.switch_to_next_key():
                            print(f"  âš ï¸ API í‚¤ í• ë‹¹ëŸ‰ ì´ˆê³¼. ë‹¤ìŒ í‚¤ë¡œ ì „í™˜...")
                            time.sleep(2)
                            continue
                
                # Store ì ‘ê·¼ ê¶Œí•œ ì—ëŸ¬
                if 'PERMISSION_DENIED' in error_str or 'file search store' in error_str.lower():
                    raise ValueError(f"Store ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
                
                # ë§ˆì§€ë§‰ ì‹œë„ë©´ ì—ëŸ¬ ì „íŒŒ
                if attempt >= max_retries - 1:
                    raise Exception(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}") from last_error
                
                time.sleep(1)
        
        raise Exception(f"ëª¨ë“  API í‚¤ì—ì„œ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(last_error)}")
    
    def load_books_info(self) -> List[Dict]:
        """saved_books_info.jsonì—ì„œ ì±… ëª©ë¡ ë¡œë“œ"""
        books_info_path = self.origin_txt_dir / "saved_books_info.json"
        
        try:
            with open(books_info_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get('books', [])
        except FileNotFoundError:
            print(f"âŒ ì±… ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {books_info_path}")
            return []
    
    def load_char_graph(self, book_title: str) -> Optional[Dict]:
        """char_graph JSON íŒŒì¼ ë¡œë“œ"""
        # ì±… ì œëª©ìœ¼ë¡œ íŒŒì¼ëª… ìƒì„± (gutenberg_idëŠ” saved_books_infoì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        # ì¼ë‹¨ ëª¨ë“  JSON íŒŒì¼ì„ ê²€ìƒ‰
        json_files = list(self.char_graph_dir.glob("*.json"))
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # íŒŒì¼ëª…ì—ì„œ ì±… ì œëª© ì¶”ì¶œí•˜ì—¬ ë§¤ì¹­ (ëŒ€ëµì )
                    # ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ saved_books_infoì˜ gutenberg_id ì‚¬ìš©
                    return data
            except Exception as e:
                continue
        
        return None
    
    def find_char_graph_file(self, gutenberg_id: int) -> Optional[Path]:
        """gutenberg_idë¡œ char_graph íŒŒì¼ ì°¾ê¸°"""
        # íŒŒì¼ëª… íŒ¨í„´: {gutenberg_id}_{book_title}.json
        pattern = f"{gutenberg_id}_*.json"
        matches = list(self.char_graph_dir.glob(pattern))
        
        if matches:
            return matches[0]
        return None
    
    def extract_characters_by_id(self, char_graph_data: Dict, target_ids: List[int] = [1, 2]) -> List[Dict]:
        """char_graphì—ì„œ idê°€ target_idsì— í•´ë‹¹í•˜ëŠ” ìºë¦­í„° ì¶”ì¶œ"""
        characters = []
        
        for char in char_graph_data.get('characters', []):
            if char.get('id') in target_ids:
                characters.append(char)
        
        # id ìˆœì„œë¡œ ì •ë ¬
        characters.sort(key=lambda x: x.get('id', 0))
        
        return characters
    
    def generate_persona(self, character: Dict, book_title: str, author: str, language: str = "en") -> str:
        """í˜ë¥´ì†Œë‚˜ ìƒì„±
        
        Args:
            character: ìºë¦­í„° ì •ë³´
            book_title: ì±… ì œëª©
            author: ì €ì
            language: ìƒì„± ì–¸ì–´ ("en" ë˜ëŠ” "ko")
        """
        character_name = character.get('common_name', '')
        description = character.get('description', '')
        names = character.get('names', [])
        
        if language == "ko":
            prompt = f"""ë‹¹ì‹ ì€ ë¬¸í•™ ì‘í’ˆì˜ ìºë¦­í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {character_name}ì˜ ìƒì„¸í•œ í˜ë¥´ì†Œë‚˜ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”:

ã€ì¤‘ìš”ã€‘ë°˜ë“œì‹œ File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.

ã€File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¾ì„ ì •ë³´ã€‘
1. {character_name}ì˜ ì£¼ìš” ëŒ€ì‚¬ ìƒ˜í”Œ (10-20ê°œ)
2. {character_name}ì´ ë“±ì¥í•˜ëŠ” ì£¼ìš” ì‚¬ê±´/ì¥ë©´ ìš”ì•½
3. {character_name}ì˜ í–‰ë™ íŒ¨í„´ ë° ê²°ì •
4. ì„œìˆ ì/ë‹¤ë¥¸ ì¸ë¬¼ì˜ {character_name}ì— ëŒ€í•œ í‰ê°€

ã€ì¸ë¬¼ ê´€ê³„ë„ ë¶„ì„ã€‘
- ìºë¦­í„° ì„¤ëª…: {description}
- ìºë¦­í„° ì´ë¦„ ë³€í˜•: {', '.join(names[:10])}

ã€ì±… ì •ë³´ã€‘
- ì±… ì œëª©: {book_title}
- ì €ì: {author}

ã€ìš”êµ¬ì‚¬í•­ã€‘
1. File Searchë¥¼ ë¨¼ì € ì‚¬ìš©í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì²´ì  ì¦ê±°ë¥¼ ì°¾ìœ¼ì„¸ìš”
2. ìºë¦­í„°ì˜ ì„±ê²©, ê°€ì¹˜ê´€, ë™ê¸°, ë°°ê²½ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„
3. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ¬ì²´ì  ì¦ê±°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±
4. ì¸ë¬¼ ê´€ê³„ë„ì—ì„œ íŒŒì•…í•œ ê´€ê³„ë¥¼ ë°˜ì˜
5. 2ì¸ì¹­ "ë‹¹ì‹ ì€..." í˜•ì‹ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ì‘ì„±
6. 200-300ë‹¨ì–´ë¡œ ì‘ì„±
7. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ì‘ì„±

í˜ë¥´ì†Œë‚˜ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”:"""
        else:  # English
            prompt = f"""You are a literary character analyst specializing in creating detailed character personas.

Write a detailed persona for {character_name} in English based on the following information:

ã€IMPORTANTã€‘You MUST use File Search to find information from the original text.

ã€Information to find using File Searchã€‘
1. Key dialogue samples from {character_name} (10-20 examples)
2. Summary of major events/scenes where {character_name} appears
3. {character_name}'s behavioral patterns and decisions
4. Narrator/other characters' evaluations of {character_name}

ã€Character Graph Analysisã€‘
- Character description: {description}
- Character name variations: {', '.join(names[:10])}

ã€Book Informationã€‘
- Book title: {book_title}
- Author: {author}

ã€Requirementsã€‘
1. First use File Search to find concrete evidence from the original text
2. Comprehensively analyze the character's personality, values, motivations, and background
3. Write based on concrete evidence from the original text
4. Reflect relationships identified in the character graph
5. Write in second person "You are..." format
6. Write 200-300 words
7. Write in clear, natural English

Write the persona in English:"""
        
        try:
            system_instruction = f"""You are a literary character analyst specializing in creating detailed character personas based on original text sources.
You MUST use File Search to find information from the original text before answering.
Be thorough, accurate, and base your analysis on concrete evidence from the source material.
Write in {language.upper()}."""
            
            persona = self._call_llm_with_file_search(prompt, system_instruction)
            return persona
        except Exception as e:
            print(f"    âŒ í˜ë¥´ì†Œë‚˜ ìƒì„± ì‹¤íŒ¨ ({language}): {str(e)}")
            return ""
    
    def generate_speaking_style(self, character: Dict, book_title: str, author: str, language: str = "en") -> str:
        """Speaking Style ìƒì„±
        
        Args:
            character: ìºë¦­í„° ì •ë³´
            book_title: ì±… ì œëª©
            author: ì €ì
            language: ìƒì„± ì–¸ì–´ ("en" ë˜ëŠ” "ko")
        """
        character_name = character.get('common_name', '')
        description = character.get('description', '')
        names = character.get('names', [])
        
        if language == "ko":
            prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ {character_name}ì˜ ë§íˆ¬(speaking style)ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”:

ã€ì¤‘ìš”ã€‘ë°˜ë“œì‹œ File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ {character_name}ì˜ ì‹¤ì œ ëŒ€ì‚¬ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.

ã€File Searchë¥¼ ì‚¬ìš©í•˜ì—¬ ì°¾ì„ ì •ë³´ã€‘
1. {character_name}ì˜ ì‹¤ì œ ëŒ€ì‚¬ ìƒ˜í”Œ (ìµœì†Œ 10ê°œ ì´ìƒ)
2. ëŒ€ì‚¬ì˜ ë¬¸ì¥ êµ¬ì¡° ë¶„ì„
3. ì‚¬ìš©í•˜ëŠ” ì–´íœ˜ì˜ íŠ¹ì§•
4. ë°˜ë³µë˜ëŠ” í‘œí˜„/êµ¬ë¬¸

ã€ìºë¦­í„° ì •ë³´ã€‘
- ìºë¦­í„° ì„¤ëª…: {description}
- ìºë¦­í„° ì´ë¦„ ë³€í˜•: {', '.join(names[:10])}
- ì±… ì œëª©: {book_title}
- ì €ì: {author}

ã€ìš”êµ¬ì‚¬í•­ã€‘
1. File Searchë¥¼ ë¨¼ì € ì‚¬ìš©í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì‹¤ì œ ëŒ€ì‚¬ë¥¼ ì°¾ìœ¼ì„¸ìš”
2. ì‹¤ì œ ëŒ€ì‚¬ íŒ¨í„´ì„ ë°˜ì˜í•˜ì—¬ í•œêµ­ì–´ë¡œ ë§í•  ë•Œì˜ ë§íˆ¬ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
3. ì‹œëŒ€ì /ì‚¬íšŒì  ë°°ê²½ì„ ê³ ë ¤
4. ìºë¦­í„°ì˜ ì„±ê²©ê³¼ ì¼ì¹˜í•˜ëŠ” ë§íˆ¬ë¡œ ì‘ì„±
5. í•œêµ­ì–´ íŠ¹ìœ ì˜ í‘œí˜„, ì–´ë¯¸, ì¡´ëŒ“ë§/ë°˜ë§ ìˆ˜ì¤€, ë¬¸ì¥ ê¸¸ì´ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ ëª…ì‹œ
6. 150-200ë‹¨ì–´ë¡œ ì‘ì„±
7. í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•˜ê²Œ ì‘ì„±

Speaking Styleì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”:"""
        else:  # English
            prompt = f"""Write the speaking style for {character_name} in English based on the following information:

ã€IMPORTANTã€‘You MUST use File Search to find {character_name}'s actual dialogue from the original text.

ã€Information to find using File Searchã€‘
1. Actual dialogue samples from {character_name} (at least 10 examples)
2. Analysis of sentence structure in dialogue
3. Characteristics of vocabulary used
4. Recurring expressions/phrases

ã€Character Informationã€‘
- Character description: {description}
- Character name variations: {', '.join(names[:10])}
- Book title: {book_title}
- Author: {author}

ã€Requirementsã€‘
1. First use File Search to find actual dialogue from the original text
2. Reflect actual dialogue patterns
3. Consider historical/social background
4. Match the character's personality
5. Write 150-200 words
6. Write in clear, natural English

Write the speaking style in English:"""
        
        try:
            system_instruction = f"""You are a literary character analyst specializing in analyzing speaking styles based on original text sources.
You MUST use File Search to find actual dialogue from the original text before answering.
Be thorough, accurate, and base your analysis on concrete evidence from the source material.
Write in {language.upper()}."""
            
            speaking_style = self._call_llm_with_file_search(prompt, system_instruction)
            return speaking_style
        except Exception as e:
            print(f"    âŒ Speaking Style ìƒì„± ì‹¤íŒ¨ ({language}): {str(e)}")
            return ""
    
    def process_book(self, book_info: Dict) -> Optional[Dict]:
        """í•œ ì±… ì²˜ë¦¬"""
        book_title = book_info.get('title', '')
        author = book_info.get('author', '')
        gutenberg_id = book_info.get('gutenberg_id')
        
        print(f"\nğŸ“– ì²˜ë¦¬ ì¤‘: {book_title}")
        print(f"   ì €ì: {author}")
        
        # char_graph íŒŒì¼ ì°¾ê¸°
        char_graph_file = self.find_char_graph_file(gutenberg_id)
        if not char_graph_file:
            print(f"   âš ï¸ char_graph íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (gutenberg_id: {gutenberg_id})")
            return None
        
        # char_graph ë°ì´í„° ë¡œë“œ
        try:
            with open(char_graph_file, 'r', encoding='utf-8') as f:
                char_graph_data = json.load(f)
        except Exception as e:
            print(f"   âŒ char_graph íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
        
        # id 1, 2ì¸ ìºë¦­í„° ì¶”ì¶œ
        characters = self.extract_characters_by_id(char_graph_data, [1, 2])
        
        if not characters:
            print(f"   âš ï¸ id 1, 2ì¸ ìºë¦­í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        print(f"   ë°œê²¬ëœ ìºë¦­í„°: {len(characters)}ëª…")
        for char in characters:
            print(f"      - {char.get('common_name')} (id: {char.get('id')})")
        
        # ê° ìºë¦­í„°ì— ëŒ€í•´ í˜ë¥´ì†Œë‚˜ì™€ speaking_style ìƒì„± (ì˜ì–´/í•œêµ­ì–´)
        result_characters = []
        
        for char in characters:
            character_name = char.get('common_name', '')
            print(f"\n   ğŸ­ {character_name} ì²˜ë¦¬ ì¤‘...")
            
            # ì˜ì–´ í˜ë¥´ì†Œë‚˜ ìƒì„±
            print(f"      ì˜ì–´ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
            persona_en = self.generate_persona(char, book_title, author, "en")
            time.sleep(1)  # API í˜¸ì¶œ ê°„ê²©
            
            # í•œêµ­ì–´ í˜ë¥´ì†Œë‚˜ ìƒì„±
            print(f"      í•œêµ­ì–´ í˜ë¥´ì†Œë‚˜ ìƒì„± ì¤‘...")
            persona_ko = self.generate_persona(char, book_title, author, "ko")
            time.sleep(1)  # API í˜¸ì¶œ ê°„ê²©
            
            # ì˜ì–´ Speaking Style ìƒì„±
            print(f"      ì˜ì–´ Speaking Style ìƒì„± ì¤‘...")
            speaking_style_en = self.generate_speaking_style(char, book_title, author, "en")
            time.sleep(1)  # API í˜¸ì¶œ ê°„ê²©
            
            # í•œêµ­ì–´ Speaking Style ìƒì„±
            print(f"      í•œêµ­ì–´ Speaking Style ìƒì„± ì¤‘...")
            speaking_style_ko = self.generate_speaking_style(char, book_title, author, "ko")
            time.sleep(1)  # API í˜¸ì¶œ ê°„ê²©
            
            if persona_en and persona_ko and speaking_style_en and speaking_style_ko:
                result_characters.append({
                    "character_name": character_name,
                    "persona": persona_en,  # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ì˜ì–´ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
                    "persona_en": persona_en,
                    "persona_ko": persona_ko,
                    "speaking_style": speaking_style_en,  # ê¸°ì¡´ í˜¸í™˜ì„±ì„ ìœ„í•´ ì˜ì–´ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ
                    "speaking_style_en": speaking_style_en,
                    "speaking_style_ko": speaking_style_ko
                })
                print(f"      âœ… ì™„ë£Œ (ì˜ì–´/í•œêµ­ì–´)")
            else:
                print(f"      âš ï¸ ì¼ë¶€ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")
                # ë¶€ë¶„ ì„±ê³µë„ ì €ì¥
                if persona_en or persona_ko or speaking_style_en or speaking_style_ko:
                    result_characters.append({
                        "character_name": character_name,
                        "persona": persona_en or "",
                        "persona_en": persona_en or "",
                        "persona_ko": persona_ko or "",
                        "speaking_style": speaking_style_en or "",
                        "speaking_style_en": speaking_style_en or "",
                        "speaking_style_ko": speaking_style_ko or ""
                    })
        
        if not result_characters:
            print(f"   âŒ ìƒì„±ëœ ìºë¦­í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ê²°ê³¼ êµ¬ì„±
        result = {
            "book_title": book_title,
            "author": author,
            "characters": result_characters
        }
        
        return result
    
    def save_character_file(self, book_title: str, data: Dict):
        """ìºë¦­í„° íŒŒì¼ ì €ì¥"""
        # íŒŒì¼ëª… ìƒì„± (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        safe_filename = "".join(c for c in book_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_filename = safe_filename.replace(' ', '_')
        filepath = self.characters_dir / f"{safe_filename}.json"
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"   ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filepath}")
        except Exception as e:
            print(f"   âŒ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
    
    def process_all_books(self):
        """ëª¨ë“  ì±… ì²˜ë¦¬"""
        print("=" * 60)
        print("ìºë¦­í„° í˜ë¥´ì†Œë‚˜ ìë™ ìƒì„± ì‹œì‘")
        print("=" * 60)
        
        # File Search Store í™•ì¸
        if not self.store_name:
            print("\nâŒ File Search Storeê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   'py scripts/setup_file_search.py'ë¥¼ ì‹¤í–‰í•˜ì—¬ Storeë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
            return
        
        print(f"\nâœ… File Search Store: {self.store_name}")
        
        # ì±… ëª©ë¡ ë¡œë“œ
        books = self.load_books_info()
        
        if not books:
            print("\nâŒ ì±… ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“š ì´ {len(books)}ê¶Œì˜ ì±…ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")
        
        # ê° ì±… ì²˜ë¦¬
        success_count = 0
        fail_count = 0
        
        for i, book in enumerate(books, 1):
            print(f"\n[{i}/{len(books)}]")
            
            try:
                result = self.process_book(book)
                
                if result:
                    self.save_character_file(book.get('title'), result)
                    success_count += 1
                else:
                    fail_count += 1
                    
            except Exception as e:
                print(f"   âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                fail_count += 1
            
            # ì±… ê°„ ê°„ê²©
            if i < len(books):
                print("\n" + "-" * 60)
                time.sleep(2)
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "=" * 60)
        print("ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"  âœ… ì„±ê³µ: {success_count}ê¶Œ")
        print(f"  âŒ ì‹¤íŒ¨: {fail_count}ê¶Œ")
        print(f"  ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.characters_dir}")
        print("=" * 60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        generator = CharacterPersonaGenerator()
        generator.process_all_books()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

