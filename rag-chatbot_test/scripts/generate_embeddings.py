"""
Gemini Embedding APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì²­í¬ì˜ ì„ë² ë”© ìƒì„±

ê° ì²­í¬ì— ëŒ€í•´ 768ì°¨ì› ë²¡í„°ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
"""

import argparse
import json
import os
from pathlib import Path
from typing import List, Dict
import time

try:
    import google.generativeai as genai
except ImportError:
    print("âŒ google-generativeai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜: pip install google-generativeai")
    exit(1)


def generate_embedding(text: str, model: str = "models/text-embedding-004") -> List[float]:
    """
    Gemini Embedding APIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
    
    Args:
        text: ì„ë² ë”©ì„ ìƒì„±í•  í…ìŠ¤íŠ¸
        model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: text-embedding-004, 768ì°¨ì›)
    
    Returns:
        768ì°¨ì› ì„ë² ë”© ë²¡í„°
    """
    try:
        result = genai.embed_content(
            model=model,
            content=text,
            task_type="retrieval_document"  # ë¬¸ì„œ ê²€ìƒ‰ìš©
        )
        return result['embedding']
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        raise


def process_chunks_file(chunks_file: str, output_dir: str, api_key: str, batch_size: int = 10) -> Dict:
    """
    ì²­í¬ íŒŒì¼ì„ ì½ì–´ ì„ë² ë”© ìƒì„± ë° ì €ì¥
    
    Args:
        chunks_file: ì²­í¬ JSON íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        api_key: Gemini API í‚¤
        batch_size: ë°°ì¹˜ í¬ê¸° (API í˜¸ì¶œ ê°„ ë”œë ˆì´)
    
    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë©”íƒ€ë°ì´í„°
    """
    # API í‚¤ ì„¤ì •
    genai.configure(api_key=api_key)
    
    # ì²­í¬ íŒŒì¼ ì½ê¸°
    print(f"ğŸ“– ì²­í¬ íŒŒì¼ ì½ê¸°: {chunks_file}")
    with open(chunks_file, "r", encoding="utf-8") as f:
        chunks_data = json.load(f)
    
    book_id = chunks_data["book_id"]
    chunks = chunks_data["chunks"]
    total_chunks = len(chunks)
    
    print(f"ğŸ“Š ì´ {total_chunks}ê°œ ì²­í¬ ì²˜ë¦¬ ì˜ˆì •")
    
    # ì„ë² ë”© ìƒì„±
    embeddings = []
    processed = 0
    
    for i, chunk in enumerate(chunks):
        text = chunk["text"]
        
        try:
            print(f"ğŸ”„ [{i+1}/{total_chunks}] ì„ë² ë”© ìƒì„± ì¤‘...", end="\r")
            embedding = generate_embedding(text)
            
            # ì²­í¬ì— ì„ë² ë”© ì¶”ê°€
            chunk["embedding"] = embedding
            embeddings.append(embedding)
            processed += 1
            
            # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
            if (i + 1) % batch_size == 0:
                time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
                
        except Exception as e:
            print(f"\nâŒ ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # ì„ë² ë”© ì‹¤íŒ¨ ì‹œ None ì €ì¥
            chunk["embedding"] = None
            continue
    
    print(f"\nâœ… {processed}/{total_chunks}ê°œ ì²­í¬ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    output_file = output_path / f"{book_id}_embeddings.json"
    
    # ì„ë² ë”©ì´ í¬í•¨ëœ ì²­í¬ ë°ì´í„° ì €ì¥
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(chunks_data, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ ì„ë² ë”© ì €ì¥ ì™„ë£Œ: {output_file}")
    
    # í†µê³„ ì •ë³´
    embedding_dim = len(embeddings[0]) if embeddings else 0
    print(f"ğŸ“Š ì„ë² ë”© ì°¨ì›: {embedding_dim}")
    print(f"ğŸ“Š ì„±ê³µë¥ : {processed/total_chunks*100:.1f}%")
    
    return {
        "book_id": book_id,
        "total_chunks": total_chunks,
        "processed_chunks": processed,
        "embedding_dim": embedding_dim,
        "output_file": str(output_file),
    }


def main():
    parser = argparse.ArgumentParser(description="Gemini Embedding APIë¡œ ì„ë² ë”© ìƒì„±")
    parser.add_argument(
        "--input",
        required=True,
        help="ì…ë ¥ ì²­í¬ JSON íŒŒì¼ ê²½ë¡œ ë˜ëŠ” ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--output",
        default="data/embeddings",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: data/embeddings)"
    )
    parser.add_argument(
        "--api-key",
        help="Gemini API í‚¤ (ë˜ëŠ” GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=10,
        help="ë°°ì¹˜ í¬ê¸° (API í˜¸ì¶œ ê°„ ë”œë ˆì´, ê¸°ë³¸: 10)"
    )
    
    args = parser.parse_args()
    
    # API í‚¤ í™•ì¸
    api_key = args.api_key or os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ Gemini API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        print("   --api-key ì˜µì…˜ ë˜ëŠ” GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
        return
    
    input_path = Path(args.input)
    
    if input_path.is_file() and input_path.suffix == ".json":
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        process_chunks_file(str(input_path), args.output, api_key, args.batch_size)
    elif input_path.is_dir():
        # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  _chunks.json íŒŒì¼ ì²˜ë¦¬
        chunk_files = list(input_path.glob("*_chunks.json"))
        print(f"ğŸ“š {len(chunk_files)}ê°œ ì²­í¬ íŒŒì¼ ë°œê²¬")
        
        for chunk_file in chunk_files:
            print(f"\n{'='*60}")
            process_chunks_file(str(chunk_file), args.output, api_key, args.batch_size)
    else:
        print(f"âŒ ì…ë ¥ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")


if __name__ == "__main__":
    main()

