"""
Gutenberg ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

ë‘ ê°€ì§€ ë°©ë²•ì„ ì§€ì›:
1. Hugging Face datasets (ì¶”ì²œ - ë¹ ë¥¸ ì‹œì‘)
2. gutenbergpy (íŠ¹ì • ì±… ì„ íƒ ì‹œ)
"""

import argparse
import json
import os
from pathlib import Path
from typing import List, Dict, Optional

# ë°©ë²• 1: Hugging Face datasets (ì¶”ì²œ)
def collect_with_datasets(book_titles: List[str], output_dir: str) -> List[Dict]:
    """
    Hugging Face datasetsë¥¼ ì‚¬ìš©í•˜ì—¬ Gutenberg ë°ì´í„° ìˆ˜ì§‘
    
    Args:
        book_titles: ìˆ˜ì§‘í•  ì±… ì œëª© ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["Pride and Prejudice", "The Great Gatsby"])
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        ìˆ˜ì§‘ëœ ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    try:
        from datasets import load_dataset
    except ImportError:
        print("âŒ datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install datasets")
        return []
    
    print("ğŸ“š Hugging Face datasetsì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ë°ì´í„°ì…‹ ë¡œë“œ (ì „ì²´ ë‹¤ìš´ë¡œë“œëŠ” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
    ds = load_dataset("sedthh/gutenberg_english", split="train")
    
    print(f"âœ… ì´ {len(ds)}ê°œ ì±… ë¡œë“œ ì™„ë£Œ")
    
    collected_books = []
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # ì±… ì œëª©ìœ¼ë¡œ í•„í„°ë§
    import json
    
    # ë¶ˆìš©ì–´ ì œê±° (ê²€ìƒ‰ì—ì„œ ì œì™¸í•  ë‹¨ì–´)
    stopwords = {"the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with", "by"}
    
    for title_keyword in book_titles:
        print(f"\nğŸ” '{title_keyword}' ê²€ìƒ‰ ì¤‘...")
        
        # ê²€ìƒ‰ í‚¤ì›Œë“œì—ì„œ ë¶ˆìš©ì–´ ì œê±°í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œë§Œ ì¶”ì¶œ
        keywords = [kw.lower() for kw in title_keyword.split() if kw.lower() not in stopwords]
        
        if not keywords:
            # ë¶ˆìš©ì–´ë§Œ ìˆìœ¼ë©´ ì›ë³¸ í‚¤ì›Œë“œ ì‚¬ìš©
            keywords = [kw.lower() for kw in title_keyword.split()]
        
        print(f"   ê²€ìƒ‰ í‚¤ì›Œë“œ: {keywords}")
        
        # METADATAì—ì„œ ì œëª©ì„ íŒŒì‹±í•´ì„œ ê²€ìƒ‰
        matching_books = []
        max_search = min(50000, len(ds))  # ìµœëŒ€ 50000ê°œê¹Œì§€ ê²€ìƒ‰
        
        for i in range(max_search):
            try:
                book = ds[i]
                # METADATA íŒŒì‹±
                metadata_str = book.get("METADATA", "")
                if not metadata_str:
                    continue
                
                metadata = json.loads(metadata_str) if isinstance(metadata_str, str) else metadata_str
                title = metadata.get("title", "")
                
                # ì œëª©ì—ì„œ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì œê±° í›„ ê²€ìƒ‰
                title_clean = title.replace("\r\n", " ").replace("\n", " ").lower()
                
                # ëª¨ë“  í•µì‹¬ í‚¤ì›Œë“œê°€ ì œëª©ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ë” ì •í™•í•œ ë§¤ì¹­)
                if all(keyword in title_clean for keyword in keywords):
                    matching_books.append((i, book, metadata))
                    print(f"   âœ… ë§¤ì¹­ ë°œê²¬: '{title.replace(chr(13), ' ').replace(chr(10), ' ').strip()}' (ì¸ë±ìŠ¤: {i})")
                    break  # ì²« ë²ˆì§¸ ì •í™•í•œ ë§¤ì¹­ë§Œ ì‚¬ìš©
            except Exception as e:
                if i < 10:  # ì²˜ìŒ 10ê°œë§Œ ì—ëŸ¬ ì¶œë ¥
                    print(f"   âš ï¸ ì¸ë±ìŠ¤ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        if len(matching_books) == 0:
            print(f"âš ï¸ '{title_keyword}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê²€ìƒ‰ ë²”ìœ„: {max_search:,}ê°œ).")
            print(f"   ì‹œë„í•œ í‚¤ì›Œë“œ: {keywords}")
            continue
        
        # ì²« ë²ˆì§¸ ë§¤ì¹­ ê²°ê³¼ ì‚¬ìš©
        idx, book, metadata = matching_books[0]
        
        # ì œëª© ì •ë¦¬
        title = metadata.get("title", "Unknown")
        title_clean = title.replace("\r\n", " ").replace("\n", " ").strip()
        
        # ì €ì ì¶”ì¶œ (authorsëŠ” ë¦¬ìŠ¤íŠ¸ì¼ ìˆ˜ ìˆìŒ)
        authors = metadata.get("authors", metadata.get("author", "Unknown"))
        if isinstance(authors, list):
            author = ", ".join(authors) if authors else "Unknown"
        elif isinstance(authors, str):
            author = authors
        else:
            author = "Unknown"
        
        # Gutenberg ID (text_id ì‚¬ìš©)
        gutenberg_id = str(metadata.get("text_id", ""))
        
        book_data = {
            "title": title_clean,
            "author": author,
            "text": book.get("TEXT", ""),
            "gutenberg_id": gutenberg_id,
        }
        
        # íŒŒì¼ë¡œ ì €ì¥
        filename = f"{book_data['title'].replace(' ', '_').replace('/', '_')}.txt"
        filepath = output_path / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(book_data["text"])
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata_path = output_path / f"{filename}.metadata.json"
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump({
                "title": book_data["title"],
                "author": book_data["author"],
                "gutenberg_id": book_data["gutenberg_id"],
                "filepath": str(filepath),
                "text_length": len(book_data["text"]),
            }, f, indent=2, ensure_ascii=False)
        
        collected_books.append(book_data)
        print(f"âœ… '{book_data['title']}' ì €ì¥ ì™„ë£Œ: {filepath}")
        print(f"   ì €ì: {book_data['author']}")
        print(f"   í…ìŠ¤íŠ¸ ê¸¸ì´: {len(book_data['text']):,} ë¬¸ì")
    
    return collected_books


# ë°©ë²• 2: gutenbergpy (íŠ¹ì • ì±… IDë¡œ ë‹¤ìš´ë¡œë“œ)
def collect_with_gutenbergpy(book_ids: List[int], output_dir: str) -> List[Dict]:
    """
    gutenbergpyë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ì±… IDë¡œ ë°ì´í„° ìˆ˜ì§‘
    
    Args:
        book_ids: Gutenberg ì±… ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: [1342, 64317])
        output_dir: ì €ì¥í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    Returns:
        ìˆ˜ì§‘ëœ ì±… ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    try:
        import gutenbergpy.textget
        import gutenbergpy.query
    except ImportError:
        print("âŒ gutenbergpy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜: pip install gutenbergpy")
        return []
    
    print("ğŸ“š gutenbergpyë¡œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    collected_books = []
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    for book_id in book_ids:
        try:
            print(f"\nğŸ” ì±… ID {book_id} ë‹¤ìš´ë¡œë“œ ì¤‘...")
            
            # í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ
            raw_text = gutenbergpy.textget.get_text_by_id(book_id)
            
            # ë°”ì´íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            if isinstance(raw_text, bytes):
                text = raw_text.decode("utf-8", errors="ignore")
            else:
                text = str(raw_text)
            
            # ë©”íƒ€ë°ì´í„° ì¡°íšŒ
            try:
                meta = gutenbergpy.query.get_metadata_by_ID(book_id)
                title = meta.get("Title", [f"Book_{book_id}"])[0] if meta else f"Book_{book_id}"
                author = meta.get("Author", ["Unknown"])[0] if meta else "Unknown"
            except:
                title = f"Book_{book_id}"
                author = "Unknown"
            
            book_data = {
                "title": title,
                "author": author,
                "text": text,
                "gutenberg_id": str(book_id),
            }
            
            # íŒŒì¼ë¡œ ì €ì¥
            filename = f"{title.replace(' ', '_').replace('/', '_')}.txt"
            filepath = output_path / filename
            
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(text)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            metadata_path = output_path / f"{filename}.metadata.json"
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump({
                    "title": title,
                    "author": author,
                    "gutenberg_id": str(book_id),
                    "filepath": str(filepath),
                    "text_length": len(text),
                }, f, indent=2, ensure_ascii=False)
            
            collected_books.append(book_data)
            print(f"âœ… '{title}' ì €ì¥ ì™„ë£Œ: {filepath}")
            print(f"   ì €ì: {author}")
            print(f"   í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text):,} ë¬¸ì")
            
        except Exception as e:
            print(f"âŒ ì±… ID {book_id} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
    
    return collected_books


def main():
    parser = argparse.ArgumentParser(description="Gutenberg ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument(
        "--method",
        choices=["datasets", "gutenbergpy"],
        default="datasets",
        help="ì‚¬ìš©í•  ìˆ˜ì§‘ ë°©ë²• (ê¸°ë³¸: datasets)"
    )
    parser.add_argument(
        "--titles",
        nargs="+",
        help="datasets ë°©ë²• ì‚¬ìš© ì‹œ: ì±… ì œëª© ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: 'Pride and Prejudice' 'The Great Gatsby')"
    )
    parser.add_argument(
        "--ids",
        type=int,
        nargs="+",
        help="gutenbergpy ë°©ë²• ì‚¬ìš© ì‹œ: Gutenberg ì±… ID ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: 1342 64317)"
    )
    parser.add_argument(
        "--output",
        default="data/raw",
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: data/raw)"
    )
    
    args = parser.parse_args()
    
    if args.method == "datasets":
        if not args.titles:
            print("âŒ datasets ë°©ë²• ì‚¬ìš© ì‹œ --titles ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("ì˜ˆì‹œ: python collect_data.py --method datasets --titles 'Pride and Prejudice'")
            return
        
        books = collect_with_datasets(args.titles, args.output)
        
    elif args.method == "gutenbergpy":
        if not args.ids:
            print("âŒ gutenbergpy ë°©ë²• ì‚¬ìš© ì‹œ --ids ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("ì˜ˆì‹œ: python collect_data.py --method gutenbergpy --ids 1342 64317")
            return
        
        books = collect_with_gutenbergpy(args.ids, args.output)
    
    print(f"\nâœ… ì´ {len(books)}ê°œ ì±… ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {args.output}")


if __name__ == "__main__":
    main()

